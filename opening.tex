\documentclass{article}
\title{Survey of Opinion-oriented Event Tracking and Summarization in Heterogeneous social network}
\author{Ningping Wang}
\begin{document}
\maketitle

Online social networks, such as Facebook, Twitter, Weibo and Renren, have achieved great success in the past years. Now Facebook has over 1 billion users and Sina Weibo has about 59 million users. It's reported that people in US are spending their 16\% online time on Facebook, even more than Google (10\%). With the rapid growth of online social networks, information is produced at an amazing speed. More than 500 million tweets are sent everyday on average. In social network, people share their opinions about various events from the Olympics to commercial promotions. Each event has several aspects (like subevents, topics). For example, in the Olympics, different

Several classical research areas in data mining are closely related to the problem, such as opinion mining, topic modeling, event detection and tracking. 

\section {Opinion Mining}
Opinion mining aims to find out people's opinion about an {\em entity} from corpus like product reviews or blogs. An entity can be a product, service, event, topic, anything that can be evaluated. An entity can be represente as a combination of different aspects (or features). For example, for an mobile phone (entity), screen, battery, memory are three aspects. Given a collection of documents $D$, the objective of opinion definition is, opinion mining aims to extract entities, aspects, associated opinions and analyse their sentiment orientations. To get a high-level perspective of the whole corpus, an addition summary step is optional.

Aspect extraction is a foundametal step in aspected-based opinion mining and is closely related with our task. The first work in aspect extraction is a two-step unsupervised method \cite{hu2004mining}. First, find frequent nouns and noun phrases. Then, find infrequent aspects by using the relationships between aspects and known opinion words. The method base on the intuition that important aspects are talked about frequently and phrases which co-occur with opinions words often are likely to be aspects. Opinion words can be generated in two ways. The dictionary-based approach defines a seed set of opinion words and search their synonyms and antoyms in a dictionary WordNet. However, it fails to capture the characteristic that the same word can express different sentiment orientation in different domains. The corpus-based approach also uses a seet set. But it finds new words by exploiting syntactic or cooccurence patterns in a large corpus\cite{hatzivassiloglou1997predicting}. The aspect extraction and opinion words finding can reinforce each other. New-found opinion words provide hint for identifying new aspects, while new aspects result in more opinion words. So many following researches combine them in a unified framework. 

More unsuperived and supervised algorithms were proposed since then. Supervised methods treat aspect extraction as a classification problem. CRF is used in \cite{jakob2010extracting}. Jin et al. \cite{jin2009opinionminer} used a HMM based sequence tagging method to find entities and opinion words simultaneously. Su et al. \cite{su2008hidden} proposed a clustering-based method to find hidden association of opinion words and aspects. Topic models can also be used in aspect extraction. However, as Titov\cite{titov2008modeling} pointed out, plain LDA is not suitable for aspect extraction because it can't distinguish global topics (like hotels in China, hotels in America) and local topics( aspects of hotels). He proposed a multi-grain LDA (MG-LDA) to solve that problem. MG-LDA models global and local topics at the same time. Another way to solve that problem is to run LDA on sentence level \cite{brody2010unsupervised}. But the two methods mess opinion words and aspects together. Zhao et al, \cite{zhao2010jointly} proposed MaxEnt-LDA to model aspect and aspect-specific opinion words jointly.

To decide the sentiment orientation of an opinion, machine learning classification methods such as SVM and naive Bayesian can be used. However, lexicon-based method can caputure more subtle semantic elements of a opinion\cite{ding2008holistic}. For example, opinion shifters like negation words (not, never, none) and sarcasm, and but-clauses. 

\section {Topic Evolution and Dynamic Topic Models}
LDA was proposed by Blei et al,\cite{blei2003latent} and has become the most popular topic modeling tool. In general, LDA is extended in three main directions. 1. Modeling more latent attributes like sentiment, social role, personal preference. 2. Incorporating inter-document relations. For example, relational LDA\cite{chang2009relational} on a citation network and author-topic LDA\cite{rosen2004author} on a author-document network. 3. Build time-aware topic model to model {\em topic evolution} in corpus, which we are most interested in.

The first try to model topic evolution with LDA is by Blei et al\cite{blei2006dynamic}. In their model, time is discretized and topic distributions satisfy Markov attribute. They chain prior $\alpha$ and $\beta$ in LDA with parameters in adjacent time slices using Gaussian distribution. A drawback of discrete-time model is we have to choose a suitable grain of time slices. In continuous dynamic topic model (cDTM) \cite{wang2012continuous}, Brownian motion is used instead of Gaussian distribution. To get rid of the Markov assumption, Wang \cite{wang2006topics} associated a Beta distribution of time with each topic to model topic popularity evolution, but topic distribtuions keep the same over time. Moreover, topic number is fixed over time. Topic birth and death are ignored. For example, at the dawn of artificial intelligence, areas like pattern recognition, natrual language processing are rarely talked about explicitly. However, they're now so important that PR and NLP should be seen as separate topics. So a {\em split} of a topic happens. A non-parametric version of dynamic topic model is given by Ahmed \cite{ahmed2012timeline}.

Apart from LDA, other methods are also used in topic evolution modeling. 

meme-tracking, short, distinctive phrases 

\section {Event Detection and Burstiness Detection}

\bibliographystyle{plain} 
\bibliography{opening.bib}
\end{document}


